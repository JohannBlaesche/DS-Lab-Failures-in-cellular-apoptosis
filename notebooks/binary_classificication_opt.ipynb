{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import optuna\n",
    "from apopfail.model import clean, get_pipeline\n",
    "from apopfail.utils.loading import load_data\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn import set_config\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "set_config(transform_output=\"pandas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, _, y = load_data(root=\"..\")\n",
    "X, y = clean(X, y)\n",
    "# X = get_pipeline(reducer=\"passthrough\", scaler=StandardScaler()).fit_transform(X)\n",
    "X = X.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=0, stratify=y\n",
    ")\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_full,\n",
    "    y_train_full,\n",
    "    test_size=0.2,\n",
    "    random_state=0,\n",
    "    stratify=y_train_full,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_xgb_param_space(trial, use_gpu=True):\n",
    "    \"\"\"Return the parameter space for XGBoost to tune.\"\"\"\n",
    "    device = \"gpu\" if use_gpu else \"cpu\"\n",
    "    n_jobs = 1 if use_gpu else -1\n",
    "    param_space = {\n",
    "        \"objective\": trial.suggest_categorical(\"objective\", [\"binary:logistic\"]),\n",
    "        \"random_state\": trial.suggest_categorical(\"random_state\", [0]),\n",
    "        \"verbosity\": trial.suggest_categorical(\"verbosity\", [0]),\n",
    "        \"n_jobs\": trial.suggest_categorical(\"n_jobs\", [n_jobs]),\n",
    "        \"device\": trial.suggest_categorical(\"device\", [device]),\n",
    "        \"early_stopping_rounds\": trial.suggest_int(\"early_stopping_rounds\", 50, 50),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 10, 63),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 200, 3300),\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 500, 2000),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.02, 0.04),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.4, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.4, 1.0),\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 1, 20.0),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 1, 30.0),\n",
    "        \"min_split_loss\": trial.suggest_float(\"min_split_loss\", 0, 2),\n",
    "    }\n",
    "    return param_space\n",
    "\n",
    "\n",
    "def get_xgb_objective(X_train, y_train, X_val, y_val, use_gpu=True):\n",
    "    \"\"\"Return the objective function for LGBM.\"\"\"\n",
    "    smote = SMOTE(sampling_strategy=0.5)\n",
    "    preprocessor = get_pipeline()\n",
    "    preprocessor.fit(X_train, y_train)\n",
    "    X_val_processed = preprocessor.transform(X_val)\n",
    "\n",
    "    def objective(trial):\n",
    "        \"\"\"Tune LGBM.\"\"\"\n",
    "        param_space = get_xgb_param_space(trial, use_gpu=use_gpu)\n",
    "        clf = XGBClassifier(**param_space)\n",
    "        model = get_pipeline(clf=clf, sampler=smote)\n",
    "        model.fit(\n",
    "            X_train,\n",
    "            y_train,\n",
    "            clf__eval_set=[(X_val_processed, y_val)],\n",
    "            clf__verbose=False,\n",
    "        )\n",
    "        y_pred = model.predict(X_val)\n",
    "        score = matthews_corrcoef(y_val, y_pred)\n",
    "        return score\n",
    "\n",
    "    return objective, X_val_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_name = \"XGBoostClassifier\"\n",
    "\n",
    "objective, X_val_processed = get_xgb_objective(\n",
    "    X_train, y_train, X_val, y_val, use_gpu=True\n",
    ")\n",
    "\n",
    "study = optuna.create_study(\n",
    "    study_name=study_name,\n",
    "    direction=\"maximize\",\n",
    "    # pruner=optuna.pruners.MedianPruner(n_warmup_steps=20),\n",
    ")\n",
    "\n",
    "study.optimize(objective, n_trials=100, show_progress_bar=True, timeout=1 * 60 * 60)\n",
    "\n",
    "best_params = study.best_params\n",
    "print(f\"Study completed with best score: {study.best_value:.4f}\")\n",
    "\n",
    "with open(f\"../output/{study_name}_best_params.json\", \"w\") as f:\n",
    "    json.dump(best_params, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
